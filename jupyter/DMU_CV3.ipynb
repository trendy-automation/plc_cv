{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "416c993c-dfa3-479c-81ac-83c4435b63ce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# PLC siemens + realsense D455 rect depth matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e7a4ea-1237-42f9-9dbc-8dda9120f4c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Snap7 PLC connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b129c-01ae-4543-800c-b661fd1f6e72",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#common variables\n",
    "found_part_num=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412a14a-d205-4cf4-91d8-d1d22b71f6a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## PLC class import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88708f56-bafd-44a9-bba9-cfd7aa1372d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../python')\n",
    "import plc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb8f95d-88b0-46d2-9588-df43028a5262",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## PLC class debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7a8e8d2-2007-43ad-a003-b811ea015cce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import snap7\n",
    "import sys\n",
    "import logging\n",
    "from logging import handlers\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import traceback\n",
    "import time\n",
    "import threading\n",
    "from snap7.util import *\n",
    "import yaml\n",
    "import os\n",
    "csd = '../python' #os.path.dirname(os.path.abspath(__file__))\n",
    "config = yaml.safe_load(open(csd+\"/config.yml\"))\n",
    "\n",
    "# TODO found_part_num\n",
    "#found_part_num = 0\n",
    "camera_db_num = config['plc']['camera_db_num']\n",
    "reconnect_timeout = config['plc']['reconnect_timeout']\n",
    "\n",
    "class PLC(threading.Thread):\n",
    "    def __init__(self, plc_ip):\n",
    "        #init\n",
    "        threading.Thread.__init__(self, args=(), name=plc_ip, kwargs=None)\n",
    "        self.plc_ip = plc_ip\n",
    "        self.found_part_num = 0\n",
    "        self.snapshotReq = False\n",
    "        self.plc_ip = plc_ip\n",
    "        self.logger = logging.getLogger(\"_plc_.client\")\n",
    "        #logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))\n",
    "        logging.basicConfig(level=config['logger']['level'],\n",
    "                            handlers=[logging.StreamHandler(sys.stdout),\n",
    "                                      logging.handlers.RotatingFileHandler(config['logger']['debug_file'],\n",
    "                                                                           maxBytes=(1048576 * 5),\n",
    "                                                                           backupCount=7)],\n",
    "                            format=config['logger']['format'])\n",
    "        self.snap7client = snap7.client.Client()\n",
    "        self.connection_ok = False\n",
    "        self.unreachable_time = 0\n",
    "        self.connect_postpone = False\n",
    "\n",
    "    def get_bool(self, db_number, offsetbyte, offsetbit):\n",
    "        return snap7.util.get_bool(self.db_read(db_number, offsetbyte, 1), 0, offsetbit)\n",
    "\n",
    "    def set_usint(self, db_number, offsetbyte, tag_value):\n",
    "        tag_data = bytearray(1)\n",
    "        snap7.util.set_usint(tag_data, 0, tag_value)\n",
    "        self.snap7client.db_write(db_number, offsetbyte, tag_data)\n",
    "        return True\n",
    "\n",
    "    def db_read(self, db_number, offsetbyte, len_arr):\n",
    "        return self.snap7client.db_read(db_number, offsetbyte, len_arr)\n",
    "\n",
    "    def db_write(self, db_number, offsetbyte, tag_data):\n",
    "        return self.snap7client.db_write(db_number, offsetbyte, tag_data)\n",
    "\n",
    "    def run(self):\n",
    "        self.logger.info(f\"Connection with PLC {self.plc_ip} started\")\n",
    "        cur_thread = threading.current_thread()\n",
    "        # Основной цикл\n",
    "        while getattr(cur_thread, \"do_run\", True):\n",
    "            try:\n",
    "                time.sleep(1.2)\n",
    "                if self.unreachable_time == 0 or (time.time() - self.unreachable_time) > reconnect_timeout:\n",
    "                    if not self.snap7client.get_connected():\n",
    "                        # Подключение к контроллеру ...\n",
    "                        try:\n",
    "                            self.connection_ok = False\n",
    "                            self.logger.info(f\"Подключение к контроллеру {self.plc_ip}...\")\n",
    "                            self.snap7client.connect(self.plc_ip, 0, 1)\n",
    "                        except Exception as error:\n",
    "                            self.logger.error(f\"Не удалось подключиться к контроллеру: {self.plc_ip}\\n\"\n",
    "                                              f\"Ошибка {str(error)} {traceback.format_exc()}\")\n",
    "                            snap7.client.logger.disabled = True\n",
    "                            self.unreachable_time = time.time()\n",
    "                    else:\n",
    "                        if not self.connection_ok:\n",
    "                            self.connection_ok = True\n",
    "                            self.unreachable_time = 0\n",
    "                            self.logger.info(f\"Соединение открыто {self.plc_ip}\")\n",
    "                            snap7.client.logger.disabled = False\n",
    "                        try:\n",
    "                            if not self.snapshotReq:\n",
    "                                self.snapshotReq = self.get_bool(db_number=camera_db_num, offsetbyte=0, offsetbit=0)\n",
    "                                if self.snapshotReq:\n",
    "                                    self.logger.info(f\"Строб съёмки пришёл {self.snapshotReq}\")\n",
    "                        except Exception as error:\n",
    "                            self.logger.error(f\"Не удалось считать строб съёмки: DB{camera_db_num}.DBX0.0\\n\"\n",
    "                                              f\"Ошибка {str(error)} {traceback.format_exc()}\")\n",
    "                            self.snap7client.disconnect()\n",
    "\n",
    "\n",
    "                        if self.snapshotReq:\n",
    "                            if self.found_part_num > 0:\n",
    "                               self.logger.info(f\"Запись результата распознования - номер найденной детали - {self.found_part_num}\")\n",
    "                               try:\n",
    "                                   self.set_usint(db_number=camera_db_num, offsetbyte=1, tag_value=self.found_part_num)\n",
    "                                   self.found_part_num = 0\n",
    "                               except Exception as error:\n",
    "                                   self.logger.error(f\"Не удалось записать результат съёмки: DB{camera_db_num}.DBB1\\n\"\n",
    "                                                     f\"Ошибка {str(error)} {traceback.format_exc()}\")\n",
    "                                   self.snap7client.disconnect()\n",
    "            except Exception as error:\n",
    "                self.logger.error(f\"Не удалось обработать цикл класса plc\\n\"\n",
    "                                  f\"Ошибка {str(error)} {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b4492f6-4fe9-48e5-92bb-00649471ea98",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_plc = PLC('192.168.1.101')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df53e06d-1ee3-43de-8027-bb2bbdb8baef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_plc.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f58cc3-0da7-43c4-8304-d4ee5202e61d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Part detection with Intel realsense D455 and OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55824400-7508-44fb-b7ed-13b3533e9c1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libusb-1.0.so.0: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m\n\u001b[1;32m     10\u001b[0m parts\u001b[38;5;241m=\u001b[39m[ \u001b[38;5;28mdict\u001b[39m(code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m8АТ-1250-11\u001b[39m\u001b[38;5;124m'\u001b[39m,part_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mКорпус маятника\u001b[39m\u001b[38;5;124m'\u001b[39m,step_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mУстанов А\u001b[39m\u001b[38;5;124m'\u001b[39m,h\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m212\u001b[39m,w\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m89\u001b[39m,Zavg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m),\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28mdict\u001b[39m(code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m8АТ-1250-11\u001b[39m\u001b[38;5;124m'\u001b[39m,part_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mКорпус маятника\u001b[39m\u001b[38;5;124m'\u001b[39m,step_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mУстанов B\u001b[39m\u001b[38;5;124m'\u001b[39m,h\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m208\u001b[39m,w\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m87\u001b[39m,Zavg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m),\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28mdict\u001b[39m(code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m8АТ-1250-11\u001b[39m\u001b[38;5;124m'\u001b[39m,part_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mКорпус маятника\u001b[39m\u001b[38;5;124m'\u001b[39m,step_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mУстанов C\u001b[39m\u001b[38;5;124m'\u001b[39m,h\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m208\u001b[39m,w\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80.6\u001b[39m,Zavg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28mdict\u001b[39m(code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m17115.2900.77\u001b[39m\u001b[38;5;124m'\u001b[39m,part_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mПереходник\u001b[39m\u001b[38;5;124m'\u001b[39m,step_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mУстанов А\u001b[39m\u001b[38;5;124m'\u001b[39m,h\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m273\u001b[39m,w\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m206\u001b[39m,Zavg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m),\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28mdict\u001b[39m(code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m17115.2900.77\u001b[39m\u001b[38;5;124m'\u001b[39m,part_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mПереходник\u001b[39m\u001b[38;5;124m'\u001b[39m,step_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mУстанов B\u001b[39m\u001b[38;5;124m'\u001b[39m,h\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m209.03\u001b[39m,w\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m206\u001b[39m,Zavg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m)]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m## License: Apache 2.0. See LICENSE file in root directory.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m## Copyright(c) 2015-2017 Intel Corporation. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m###############################################\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m##      Open CV and Numpy integration        ##\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m###############################################\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyrealsense2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mrs\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#import matplotlib.pyplot as plt \u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyrealsense2/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# py libs (pyd/so) should be copied to pyrealsense2 folder\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyrealsense2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: libusb-1.0.so.0: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "#var huck\n",
    "found_part_num = 0\n",
    "teach_part_num = 0\n",
    "\n",
    "#separate file - configurations of parts and settings\n",
    "tolerance = 0.05\n",
    "resolution_x,resolution_y=640,480\n",
    "#resolution_x,resolution_y=1280,720\n",
    "fps=30\n",
    "parts=[ dict(code='8АТ-1250-11',part_name='Корпус маятника',step_name='Установ А',h=212,w=89,Zavg=400),\n",
    "        dict(code='8АТ-1250-11',part_name='Корпус маятника',step_name='Установ B',h=208,w=87,Zavg=400),\n",
    "        dict(code='8АТ-1250-11',part_name='Корпус маятника',step_name='Установ C',h=208,w=80.6,Zavg=400),\n",
    "        dict(code='8АТ-1250-11',part_name='Корпус маятника',step_name='Установ D',h=208,w=80,Zavg=400),\n",
    "        dict(code='8АТ-1250-11',part_name='Корпус маятника',step_name='Установ E',h=528,w=268,Zavg=400),\n",
    "        dict(code='17115.2900.77',part_name='Переходник',step_name='Установ А',h=273,w=206,Zavg=400),\n",
    "        dict(code='17115.2900.77',part_name='Переходник',step_name='Установ B',h=209.03,w=206,Zavg=400)]\n",
    "\n",
    "## License: Apache 2.0. See LICENSE file in root directory.\n",
    "## Copyright(c) 2015-2017 Intel Corporation. All Rights Reserved.\n",
    "\n",
    "###############################################\n",
    "##      Open CV and Numpy integration        ##\n",
    "###############################################\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "#import opencv_jupyter_ui as jcv2\n",
    "\n",
    "\n",
    "import cv2\n",
    "#from transform import hough_windowed_rectangle, hough_cricles\n",
    "#from utils import plot_hough_space, graph_output, graph_rectangles_and_circles, countMoney\n",
    "#from skimage.io import imshow\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "template = cv2.imread(\"part1.png\")\n",
    "\n",
    "\n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "# Get device product line for setting a supporting resolution\n",
    "pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "device = pipeline_profile.get_device()\n",
    "#depth_sensor = device.first_depth_sensor()\n",
    "device_product_line = str(device.get_info(rs.camera_info.product_line))\n",
    "print('device_product_line',device_product_line)\n",
    "\n",
    "found_rgb = False\n",
    "for s in device.sensors:\n",
    "    if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "        found_rgb = True\n",
    "        break\n",
    "if not found_rgb:\n",
    "    print(\"The demo requires Depth camera with Color sensor\")\n",
    "    exit(0)\n",
    "align = rs.align(rs.stream.color)\n",
    "config.enable_stream(rs.stream.depth, resolution_x, resolution_y, rs.format.z16, fps)\n",
    "config.enable_stream(rs.stream.color, resolution_x, resolution_y, rs.format.bgr8, fps)\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "try:\n",
    "    while True:\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "        \n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        \n",
    "        frames = []\n",
    "        for x in range(15):\n",
    "            frameset = pipeline.wait_for_frames()\n",
    "            frames.append(frameset.get_depth_frame())\n",
    "        \n",
    "        hole_filling = rs.hole_filling_filter()\n",
    "        for x in range(15):\n",
    "            frame = hole_filling.process(frames[x])\n",
    "            frames[x] = np.asanyarray(frame.get_data())\n",
    "        \n",
    "        depth_image = np.min(frames, axis=0)\n",
    "        # print(np.min(depth_image),np.max(depth_image))\n",
    "        # depth_image = depth_image.astype(dtype=np.uint8)\n",
    "        # #depth_image = cv2.cvtColor(depth_image,cv2.COLOR_BGR2GRAY)\n",
    "        # depth_image = cv2.adaptiveThreshold(depth_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,51,9)\n",
    "        # #depth_image = cv2.adaptiveThreshold(depth_image,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2)\n",
    "        # #depth_image = cv2.adaptiveThreshold(depth_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "        # Calculate the min along the time axis\n",
    "        #depth_image = np.min(frames, axis=0).astype(dtype=np.uint16)\n",
    "        \n",
    "        ##hight normalization for template search\n",
    "        #resultimage = np.zeros((resolution_x,resolution_y))\n",
    "        #depth_image = cv2.normalize(depth_image, resultimage, 0, 100, cv2.NORM_MINMAX)\n",
    "        \n",
    "        depth_image = depth_image.astype(dtype=np.uint16)\n",
    "        #depth_image = cv2.medianBlur(depth_image,5)\n",
    "       \n",
    "        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
    "        depth_image = cv2.convertScaleAbs(depth_image, alpha=0.3)\n",
    "        depth_image2 = depth_image.copy()\n",
    "        \n",
    "        part_area = 10\n",
    "        x, y = resolution_x//2-53, resolution_y//2+27\n",
    "        w, h = resolution_x//part_area, resolution_y//part_area  \n",
    "        crop_img = depth_image[x-w:x+w, y-h:y+h]\n",
    "        #crop_img[crop_img<10] = 255\n",
    "        min_hight_color = np.min(crop_img)\n",
    "        depth_image[depth_image<min_hight_color]=255\n",
    "        #depth_image2[depth_image2<min_hight_color]=255\n",
    "        print('max_hight_color', min_hight_color)\n",
    "        depth_image = depth_image - min_hight_color\n",
    "        \n",
    "        \n",
    "        cv2.rectangle(depth_image, (x-w,y-h), (x+w,y+h), (255,0,0), 1, 16)\n",
    "\n",
    "        \n",
    "        #constants\n",
    "        centre_x,centre_y = resolution_x//2-53, resolution_y//2+27\n",
    "        trust_interval=[320,490]\n",
    "        min_spot=20\n",
    "        \n",
    "        x1,y1 = int(centre_x-min_spot//2), int(centre_y-min_spot//2)\n",
    "        x2,y2 = int(centre_x+min_spot//2), int(centre_y+min_spot//2)\n",
    "        cropped_image = depth_image[x1:x2,y1:y2]\n",
    "        Cmean = np.mean(cropped_image)       \n",
    "        \n",
    "        #monochrome view\n",
    "        #depth_image[depth_image<Cmean-15]=0\n",
    "        #depth_image[depth_image>Cmean+15]=0        \n",
    "        #depth_image[depth_image>0]=255        \n",
    "        \n",
    "                \n",
    "        #contours = cv2.findContours(depth_image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours, _  = cv2.findContours(depth_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        #print(len(contours))\n",
    "        bboxes = []\n",
    "        rboxes = []\n",
    "        cnts = []\n",
    "        k=-1.5\n",
    "        b=565\n",
    "        Zavg = k*Cmean+b\n",
    "        for cnt in contours:\n",
    "            ## Skip non-central area\n",
    "            if cv2.pointPolygonTest(cnt, (centre_x,centre_y), True)<0:\n",
    "                continue\n",
    "            ## Get the stright bounding rect\n",
    "            bbox = cv2.boundingRect(cnt)\n",
    "            x,y,w,h = bbox\n",
    "            if w<30 or h < 30 or w*h < 2000 or w > 500:\n",
    "                continue\n",
    "\n",
    "            ## Draw rect\n",
    "            cv2.rectangle(depth_image, (x,y), (x+w,y+h), (255,0,0), 1, 16)\n",
    "\n",
    "            ## Get the rotated rect\n",
    "            rbox = cv2.minAreaRect(cnt)\n",
    "            (x1,y1), (cw,ch), rot_angle = rbox\n",
    "            x1=int(x1)\n",
    "            y1=int(y1)\n",
    "            cw=int(cw)\n",
    "            ch=int(ch)\n",
    "            #print ((x1,y1), (cw,ch))\n",
    "            ## Draw rotated rect\n",
    "            #!!!!!!!!!not worked!!!!!\n",
    "            #cv2.rectangle(depth_image, (x1,y1), (x1+cw,y1+ch), (255,0,0), 1, 16)\n",
    "            #print(\"rot_angle:\", rot_angle)  \n",
    "\n",
    "            ## backup \n",
    "            bboxes.append(bbox)\n",
    "            rboxes.append(rbox)\n",
    "            cnts.append(cnt)\n",
    "            \n",
    "\n",
    "            # cv2.putText(depth_colormap, f\"Zavg {round(Zavg, 1)} mm\", (int(x1 - 20), int(y1 - 20)), cv2.FONT_HERSHEY_PLAIN, 2, (100, 200, 0), 2)\n",
    "            # cv2.putText(color_image, f\"Zavg {round(Zavg, 1)} mm\", (int(x1 - 20), int(y1 - 20)), cv2.FONT_HERSHEY_PLAIN, 2, (100, 200, 0), 2)\n",
    "            #print(f'w {hw[1]} h {hw[0]} Zavg {Zavg}')\n",
    "            pk=0.003125\n",
    "            pb=-0.125\n",
    "            part_w = cw*(pk*Zavg+pb)\n",
    "            part_h = ch*(pk*Zavg+pb)\n",
    "            #print(f'part_w {part_w} part_h {part_h}')\n",
    "            cv2.putText(depth_image, f\"{round(part_h, 0)} x {round(part_w, 0)} mm\", (int(x1 - 20), int(y1 - 20)), cv2.FONT_HERSHEY_PLAIN, 2, (100, 200, 0), 2)\n",
    "            cv2.putText(color_image, f\"{round(part_h, 0)} x {round(part_w, 0)} mm\", (int(x1 - 20), int(y1 - 20)), cv2.FONT_HERSHEY_PLAIN, 2, (100, 200, 0), 2)\n",
    "            \n",
    "        depth_colormap = cv2.applyColorMap(depth_image, cv2.COLORMAP_JET)\n",
    "        h, w = template.shape[:2]\n",
    "        methods = [cv2.TM_SQDIFF_NORMED, cv2.TM_CCORR_NORMED, cv2.TM_CCOEFF_NORMED]\n",
    "        res = cv2.matchTemplate(depth_colormap, template, methods[2])\n",
    "        threshold = 0.8\n",
    "        loc = np.where(res >= threshold)  # Coordinates y, x where the matching degree is greater than %80\n",
    "        print(loc)\n",
    "        for pt in zip(*loc[::-1]):  # * Indicates optional parameters\n",
    "            right_bottom = (pt[0] + w, pt[1] + h)\n",
    "            cv2.rectangle(depth_colormap, pt, right_bottom, (0, 0, 255), 1)\n",
    "\n",
    "        \n",
    "        depth_colormap2 = cv2.applyColorMap(depth_image2, cv2.COLORMAP_JET)\n",
    "                \n",
    "        # rectangle = np.array([[x1,y1],[x2,y1],[x2,y2],[x1,y2],[x1,y1]], np.int32)\n",
    "        # depth_colormap =cv2.polylines(depth_colormap, [rectangle], False, (255,0,0), thickness=1)\n",
    "        # color_image =cv2.polylines(color_image, [rectangle], False, (255,0,0), thickness=1)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        last_found_part_num = found_part_num \n",
    "        found_part_num = 0\n",
    "        for num, part in enumerate(parts):\n",
    "            h, w, Zavg = part['h'], part['w'], part['Zavg']\n",
    "            part_name, step_name = part['part_name'],part['step_name']\n",
    "            if trust_interval[0]<Zavg<trust_interval[1]:\n",
    "                x1,y1 = int(centre_x-w//2), int(centre_y-h//2)\n",
    "                x2,y2 = int(centre_x+w//2), int(centre_y+h//2)\n",
    "                cropped_image = depth_colormap[x1:x2,y1:y2]\n",
    "                Cavg = np.mean(cropped_image)\n",
    "                CurZavg = k*Cavg+b\n",
    "                \n",
    "                if Zavg*(1-tolerance)<CurZavg<Zavg*(1+tolerance):\n",
    "                    if found_part_num==0:\n",
    "                        found_part_name=part_name\n",
    "                        found_part_step=step_name\n",
    "                        found_part_num=num\n",
    "                        rectangle = np.array([[x1,y1],[x2,y1],[x2,y2],[x1,y2],[x1,y1]], np.int32)\n",
    "                       \n",
    "                        depth_colormap =cv2.polylines(depth_colormap, [rectangle], False, (0,255,0), thickness=1)\n",
    "                        color_image =cv2.polylines(color_image, [rectangle], False, (0,255,0), thickness=1)\n",
    "                        if last_found_part_num != found_part_num:\n",
    "                            print(f'Part detected: {part_name} {step_name}')\n",
    "                    else:\n",
    "                        print(f'warning! several parts detected {part_name} {step_name} and {found_part_name} {found_part_step}')\n",
    "                        found_part_num=0\n",
    "                        break\n",
    "            else:\n",
    "                print(f'warning! part {num} have wrong Zavg {Zavg}. Trust interval is {trust_interval}')\n",
    "\n",
    "        #diagonal draw \n",
    "        #depth_colormap =cv2.polylines(depth_colormap, [np.array([[0,0],[resolution_x,resolution_y]], np.int32)], False, (0,255,0), thickness=1)\n",
    "        #color_image =cv2.polylines(color_image, [np.array([[0,0],[resolution_x,resolution_y]], np.int32)], False, (0,255,0), thickness=1)\n",
    "         \n",
    "        depth_colormap_dim = depth_colormap.shape\n",
    "        color_colormap_dim = color_image.shape\n",
    "        \n",
    "        \n",
    "\n",
    "        # If depth and color resolutions are different, resize color image to match depth image for display\n",
    "        if depth_colormap_dim != color_colormap_dim:\n",
    "            resized_color_image = cv2.resize(color_image, dsize=(depth_colormap_dim[1], depth_colormap_dim[0]), interpolation=cv2.INTER_AREA)\n",
    "            images = np.hstack((depth_colormap,resized_color_image))\n",
    "        else:\n",
    "            #images = np.hstack((depth_colormap, color_image))\n",
    "            images = np.hstack((depth_colormap, depth_colormap2))\n",
    "\n",
    "        # Show images\n",
    "        cv2.startWindowThread()\n",
    "        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('RealSense', images)\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "finally: \n",
    "\n",
    "    # Stop streaming\n",
    "    pipeline.stop() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59707ae-3e0f-47a2-8c45-15df3fcc1613",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3fb9e4-8e10-4c3f-8153-2033bfaa9479",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def template_demo():\n",
    "    tpl = cv.imread(\"./files/images/match2.png\")\n",
    "    target = cv.imread(\"./files/images/match1.png\")\n",
    "\n",
    "    methods = [cv.TM_SQDIFF_NORMED, cv.TM_CCORR_NORMED, cv.TM_CCOEFF_NORMED]  # Only test these three template matching methods\n",
    "    th, tw = tpl.shape[:2] #Take length and width\n",
    "\n",
    "    for md in methods:\n",
    "        print(md)\n",
    "        result = cv.matchTemplate(target, tpl, md)  # Get matching results\n",
    "        min_val, max_val, min_loc, max_loc = cv.minMaxLoc(result)\n",
    "        if md == cv.TM_SQDIFF_NORMED:  # cv.TM_SQDIFF_NORMED is the most similar when it is the smallest, most similar when the others are the largest\n",
    "            tl = min_loc\n",
    "        else:\n",
    "            tl = max_loc\n",
    "\n",
    "        br = (tl[0] + tw, tl[1] + th)\n",
    "        cv.rectangle(target, tl, br, (0, 0, 255), 2)  # tl is the coordinates of the upper left corner, br is the coordinates of the lower right corner, so as to draw a rectangle\n",
    "        cv.imshow(\"match-\"+np.str(md), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9059f970-839f-4005-9bf7-c2ca8f945572",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def template_demo_more():\n",
    "    img_rgb = cv.imread('./files/images/temp1.jpg')\n",
    "    img_gray = cv.cvtColor(img_rgb, cv.COLOR_BGR2GRAY)\n",
    "    template = cv.imread('./files/images/temp2.jpg', 0)\n",
    "    h, w = template.shape[:2]\n",
    "\n",
    "    res = cv.matchTemplate(img_gray, template, cv.TM_CCOEFF_NORMED)\n",
    "    threshold = 0.8\n",
    "\n",
    "    loc = np.where(res >= threshold)  # Coordinates y, x where the matching degree is greater than %80\n",
    "    print(loc)\n",
    "    for pt in zip(*loc[::-1]):  # * Indicates optional parameters\n",
    "        right_bottom = (pt[0] + w, pt[1] + h)\n",
    "        cv.rectangle(img_rgb, pt, right_bottom, (0, 0, 255), 2)\n",
    "        cv.imshow(\"more\",img_rgb)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179aef01-9caf-4ce3-aa04-5f3f392a8498",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
