{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "416c993c-dfa3-479c-81ac-83c4435b63ce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# PLC siemens + realsense D455 rect depth matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e7a4ea-1237-42f9-9dbc-8dda9120f4c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Snap7 PLC connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b129c-01ae-4543-800c-b661fd1f6e72",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#common variables\n",
    "found_part_num=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412a14a-d205-4cf4-91d8-d1d22b71f6a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## PLC class import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88708f56-bafd-44a9-bba9-cfd7aa1372d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../python')\n",
    "import plc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb8f95d-88b0-46d2-9588-df43028a5262",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## PLC class debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a8e8d2-2007-43ad-a003-b811ea015cce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../python/config.yml'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m     12\u001B[0m csd \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../python\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;66;03m#os.path.dirname(os.path.abspath(__file__))\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m config \u001B[38;5;241m=\u001B[39m yaml\u001B[38;5;241m.\u001B[39msafe_load(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcsd\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/config.yml\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# TODO found_part_num\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m#found_part_num = 0\u001B[39;00m\n\u001B[0;32m     17\u001B[0m camera_db_num \u001B[38;5;241m=\u001B[39m config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mplc\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcamera_db_num\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32mD:\\Work\\DMU85\\PLC_CV\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    279\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    280\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    281\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    282\u001B[0m     )\n\u001B[1;32m--> 284\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m io_open(file, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../python/config.yml'"
     ]
    }
   ],
   "source": [
    "import snap7\n",
    "import sys\n",
    "import logging\n",
    "from logging import handlers\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import traceback\n",
    "import time\n",
    "import threading\n",
    "from snap7.util import *\n",
    "import yaml\n",
    "import os\n",
    "csd = '../python' #os.path.dirname(os.path.abspath(__file__))\n",
    "config = yaml.safe_load(open(csd+\"/config.yml\"))\n",
    "\n",
    "# TODO found_part_num\n",
    "#found_part_num = 0\n",
    "camera_db_num = config['plc']['camera_db_num']\n",
    "reconnect_timeout = config['plc']['reconnect_timeout']\n",
    "\n",
    "class PLC(threading.Thread):\n",
    "    def __init__(self, plc_ip):\n",
    "        #init\n",
    "        threading.Thread.__init__(self, args=(), name=plc_ip, kwargs=None)\n",
    "        self.plc_ip = plc_ip\n",
    "        self.found_part_num = 0\n",
    "        self.snapshotReq = False\n",
    "        self.plc_ip = plc_ip\n",
    "        self.logger = logging.getLogger(\"_plc_.client\")\n",
    "        #logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))\n",
    "        logging.basicConfig(level=config['logger']['level'],\n",
    "                            handlers=[logging.StreamHandler(sys.stdout),\n",
    "                                      logging.handlers.RotatingFileHandler(config['logger']['debug_file'],\n",
    "                                                                           maxBytes=(1048576 * 5),\n",
    "                                                                           backupCount=7)],\n",
    "                            format=config['logger']['format'])\n",
    "        self.snap7client = snap7.client.Client()\n",
    "        self.connection_ok = False\n",
    "        self.unreachable_time = 0\n",
    "        self.connect_postpone = False\n",
    "\n",
    "    def get_bool(self, db_number, offsetbyte, offsetbit):\n",
    "        return snap7.util.get_bool(self.db_read(db_number, offsetbyte, 1), 0, offsetbit)\n",
    "\n",
    "    def set_usint(self, db_number, offsetbyte, tag_value):\n",
    "        tag_data = bytearray(1)\n",
    "        snap7.util.set_usint(tag_data, 0, tag_value)\n",
    "        self.snap7client.db_write(db_number, offsetbyte, tag_data)\n",
    "        return True\n",
    "\n",
    "    def db_read(self, db_number, offsetbyte, len_arr):\n",
    "        return self.snap7client.db_read(db_number, offsetbyte, len_arr)\n",
    "\n",
    "    def db_write(self, db_number, offsetbyte, tag_data):\n",
    "        return self.snap7client.db_write(db_number, offsetbyte, tag_data)\n",
    "\n",
    "    def run(self):\n",
    "        self.logger.info(f\"Connection with PLC {self.plc_ip} started\")\n",
    "        cur_thread = threading.current_thread()\n",
    "        # Основной цикл\n",
    "        while getattr(cur_thread, \"do_run\", True):\n",
    "            try:\n",
    "                time.sleep(1.2)\n",
    "                if self.unreachable_time == 0 or (time.time() - self.unreachable_time) > reconnect_timeout:\n",
    "                    if not self.snap7client.get_connected():\n",
    "                        # Подключение к контроллеру ...\n",
    "                        try:\n",
    "                            self.connection_ok = False\n",
    "                            self.logger.info(f\"Подключение к контроллеру {self.plc_ip}...\")\n",
    "                            self.snap7client.connect(self.plc_ip, 0, 1)\n",
    "                        except Exception as error:\n",
    "                            self.logger.error(f\"Не удалось подключиться к контроллеру: {self.plc_ip}\\n\"\n",
    "                                              f\"Ошибка {str(error)} {traceback.format_exc()}\")\n",
    "                            snap7.client.logger.disabled = True\n",
    "                            self.unreachable_time = time.time()\n",
    "                    else:\n",
    "                        if not self.connection_ok:\n",
    "                            self.connection_ok = True\n",
    "                            self.unreachable_time = 0\n",
    "                            self.logger.info(f\"Соединение открыто {self.plc_ip}\")\n",
    "                            snap7.client.logger.disabled = False\n",
    "                        try:\n",
    "                            if not self.snapshotReq:\n",
    "                                self.snapshotReq = self.get_bool(db_number=camera_db_num, offsetbyte=0, offsetbit=0)\n",
    "                                if self.snapshotReq:\n",
    "                                    self.logger.info(f\"Строб съёмки пришёл {self.snapshotReq}\")\n",
    "                        except Exception as error:\n",
    "                            self.logger.error(f\"Не удалось считать строб съёмки: DB{camera_db_num}.DBX0.0\\n\"\n",
    "                                              f\"Ошибка {str(error)} {traceback.format_exc()}\")\n",
    "                            self.snap7client.disconnect()\n",
    "\n",
    "\n",
    "                        if self.snapshotReq:\n",
    "                            if self.found_part_num > 0:\n",
    "                               self.logger.info(f\"Запись результата распознования - номер найденной детали - {self.found_part_num}\")\n",
    "                               try:\n",
    "                                   self.set_usint(db_number=camera_db_num, offsetbyte=1, tag_value=self.found_part_num)\n",
    "                                   self.found_part_num = 0\n",
    "                               except Exception as error:\n",
    "                                   self.logger.error(f\"Не удалось записать результат съёмки: DB{camera_db_num}.DBB1\\n\"\n",
    "                                                     f\"Ошибка {str(error)} {traceback.format_exc()}\")\n",
    "                                   self.snap7client.disconnect()\n",
    "            except Exception as error:\n",
    "                self.logger.error(f\"Не удалось обработать цикл класса plc\\n\"\n",
    "                                  f\"Ошибка {str(error)} {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4492f6-4fe9-48e5-92bb-00649471ea98",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_plc = PLC('192.168.1.101')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df53e06d-1ee3-43de-8027-bb2bbdb8baef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_plc.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f58cc3-0da7-43c4-8304-d4ee5202e61d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Part detection with Intel realsense D455 and OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6701ed56-27cd-4a14-8fca-54d2139dc950",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaleAbs_alpha = 0.3\n",
    "threshold = 0.65\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55824400-7508-44fb-b7ed-13b3533e9c1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#var huck\n",
    "found_part_num = 0\n",
    "teach_part_num = 0\n",
    "\n",
    "#separate file - configurations of parts and settings\n",
    "tolerance = 0.05\n",
    "scaleAbs_alpha = 0.3\n",
    "threshold = 0.65\n",
    "#resolution_x,resolution_y=640,480\n",
    "resolution_x,resolution_y=848,480\n",
    "#resolution_x,resolution_y=1280,720\n",
    "fps=5\n",
    "parts=[ dict(code='8АТ-1250-11',part_name='Корпус маятника',step_name='Установ А',h=212,w=89,Zavg=400),\n",
    "        dict(code='8АТ-1250-11',part_name='Корпус маятника',step_name='Установ B',h=208,w=87,Zavg=400),\n",
    "        dict(code='8АТ-1250-11',part_name='Корпус маятника',step_name='Установ C',h=208,w=80.6,Zavg=400),\n",
    "        dict(code='8АТ-1250-11',part_name='Корпус маятника',step_name='Установ D',h=208,w=80,Zavg=400),\n",
    "        dict(code='8АТ-1250-11',part_name='Корпус маятника',step_name='Установ E',h=528,w=268,Zavg=400),\n",
    "        dict(code='17115.2900.77',part_name='Переходник',step_name='Установ А',h=273,w=206,Zavg=400),\n",
    "        dict(code='17115.2900.77',part_name='Переходник',step_name='Установ B',h=209.03,w=206,Zavg=400)]\n",
    "\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import pyshine as ps\n",
    "import socket\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "templateDir = 'templates'\n",
    "lstdr = os.listdir(templateDir)\n",
    "parts = [f for f in lstdr if os.path.isdir(templateDir+'/'+f)] \n",
    "templates = {str(p):[f for f in os.listdir(templateDir+'/'+p) if os.path.isfile(templateDir+'/'+p+'/'+f) and f.endswith('.png')] for p in parts} \n",
    "\n",
    "HTML=f\"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<center><img src=\"stream.mjpg\" width='{resolution_x*2}' height='{resolution_y}' autoplay playsinline></center>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "StreamProps = ps.StreamProps\n",
    "StreamProps.set_Page(StreamProps,HTML)\n",
    "address = (socket.gethostbyname(socket.gethostname()),9001) # Enter your IP address \n",
    "\n",
    "\n",
    "class ImgCapture():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def read(self):\n",
    "\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        self.frames = pipeline.wait_for_frames()\n",
    "        depth_frame = self.frames.get_depth_frame()\n",
    "        color_frame = self.frames.get_color_frame()\n",
    "        \"\"\"\n",
    "        # Convert images to numpy arrays\n",
    "        #depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        frames = []\n",
    "        for x in range(15):\n",
    "            frameset = pipeline.wait_for_frames()\n",
    "            frames.append(frameset.get_depth_frame())\n",
    "        \n",
    "        hole_filling = rs.hole_filling_filter()\n",
    "        for x in range(15):\n",
    "            frame = hole_filling.process(frames[x])\n",
    "            frames[x] = np.asanyarray(frame.get_data())\n",
    "        depth_image = np.min(frames, axis=0)        \n",
    "        \"\"\"\n",
    "        hole_filling = rs.hole_filling_filter()\n",
    "        depth_frame = hole_filling.process(depth_frame)\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        \n",
    "        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=scaleAbs_alpha), cv2.COLORMAP_JET)\n",
    "        depth_colormap_dim = depth_colormap.shape\n",
    "        color_colormap_dim = color_image.shape\n",
    "        \n",
    "        #print (f\"templates loop for {templates}\")\n",
    "        for part, pics in templates.items():\n",
    "            #print (f\"look for part {part}\")\n",
    "            for file in pics:\n",
    "                #print (f\"look for template {template}\")\n",
    "                template = cv2.imread(f\"{templateDir}/{part}/{file}\")\n",
    "                h, w = template.shape[:2]\n",
    "                methods = [cv2.TM_SQDIFF_NORMED, cv2.TM_CCORR_NORMED, cv2.TM_CCOEFF_NORMED]\n",
    "                res = cv2.matchTemplate(depth_colormap, template, methods[2])\n",
    "                loc = np.where(res >= threshold)  # Coordinates y, x where the matching degree is greater than threshold\n",
    "                #print(\"loc\", loc)\n",
    "                #for pt in zip(*loc[::-1]):  # * Indicates optional parameters\n",
    "                if len(loc[0])>0:\n",
    "                    print (f\"Part {part} found\" )\n",
    "                    pt = list(zip(*loc[::-1]))[0]\n",
    "                    right_bottom = (pt[0] + w, pt[1] + h)\n",
    "                    cv2.rectangle(depth_colormap, pt, right_bottom, (0, 0, 255), 1)\n",
    "                    continue\n",
    "        \n",
    "        # If depth and color resolutions are different, resize color image to match depth image for display\n",
    "        if depth_colormap_dim != color_colormap_dim:\n",
    "            color_image = cv2.resize(color_image, dsize=(depth_colormap_dim[1], depth_colormap_dim[0]), interpolation=cv2.INTER_AREA)\n",
    "        images = np.hstack((depth_colormap, color_image))\n",
    "        \n",
    "        if images is not None:\n",
    "            ret = True\n",
    "        return(ret, images)\n",
    "\n",
    "    def isOpened(self):\n",
    "        ret, _, _ = self.rs.get_frame_stream()\n",
    "        return(ret)   \n",
    "        \n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "# Get device product line for setting a supporting resolution\n",
    "pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "device = pipeline_profile.get_device()\n",
    "#depth_sensor = device.first_depth_sensor()\n",
    "device_product_line = str(device.get_info(rs.camera_info.product_line))\n",
    "print('device_product_line',device_product_line)\n",
    "\n",
    "found_rgb = False\n",
    "for s in device.sensors:\n",
    "    if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "        found_rgb = True\n",
    "        break\n",
    "if not found_rgb:\n",
    "    print(\"The demo requires Depth camera with Color sensor\")\n",
    "    exit(0)\n",
    "align = rs.align(rs.stream.color)\n",
    "config.enable_stream(rs.stream.depth, resolution_x, resolution_y, rs.format.z16, fps)\n",
    "config.enable_stream(rs.stream.color, resolution_x, resolution_y, rs.format.bgr8, fps)\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "try:\n",
    "    StreamProps.set_Mode(StreamProps,'cv2')\n",
    "    capImages = ImgCapture()\n",
    "    StreamProps.set_Capture(StreamProps, capImages)\n",
    "    StreamProps.set_Quality(StreamProps, 90)\n",
    "    server = ps.Streamer(address, StreamProps)\n",
    "    print('Server started at','http://'+address[0]+':'+str(address[1]))\n",
    "    server.serve_forever()\n",
    "    while True:\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "finally: \n",
    "    # Stop streaming\n",
    "    pipeline.stop() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59707ae-3e0f-47a2-8c45-15df3fcc1613",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3fb9e4-8e10-4c3f-8153-2033bfaa9479",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "#import numpy as np\n",
    "\n",
    "def template_demo():\n",
    "    target = cv.imread(\"./templates/2/part4.png\")\n",
    "    tpl = cv.imread(\"./templates/2/part7.png\")\n",
    "\n",
    "\n",
    "    methods = [cv.TM_SQDIFF_NORMED, cv.TM_CCORR_NORMED, cv.TM_CCOEFF_NORMED]  # Only test these three template matching methods\n",
    "\n",
    "    for md in methods:\n",
    "        #print(md)\n",
    "        #correlation = cv2.matchTemplate(target, tpl, cv2.TM_CCORR_NORMED, mask=mask)\n",
    "        #res = cv.matchTemplate(target, tpl, md, mask=mask)  # Get matching results\n",
    "        # Match with template as both template and mask parameter\n",
    "        res = cv.matchTemplate(target, tpl, md, None, tpl.copy())\n",
    "        min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "        if md == cv.TM_SQDIFF_NORMED:  # cv.TM_SQDIFF_NORMED is the most similar when it is the smallest, most similar when the others are the largest\n",
    "            tl = min_loc\n",
    "        else:\n",
    "            tl = max_loc\n",
    "        loc = np.where(res >= max_val)\n",
    "        #cv.rectangle(target, tl, br, (0, 0, 255), 2)  # tl is the coordinates of the upper left corner, br is the coordinates of the lower right corner, so as to draw a rectangle\n",
    "        #cv.imshow(\"match-\"+str(md), target)\n",
    "        print(md, min_val, max_val,tl)\n",
    "template_demo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179aef01-9caf-4ce3-aa04-5f3f392a8498",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib as mpl\n",
    "\n",
    "box_points = []\n",
    "button_down = False\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, -angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result\n",
    "\n",
    "def scale_image(image, percent, maxwh):\n",
    "    color_scale_rate = 0\n",
    "    max_width = maxwh[1]\n",
    "    max_height = maxwh[0]\n",
    "    max_percent_width = max_width / image.shape[1] * 100\n",
    "    max_percent_height = max_height / image.shape[0] * 100\n",
    "    max_percent = 0\n",
    "    if max_percent_width < max_percent_height:\n",
    "        max_percent = max_percent_width\n",
    "    else:\n",
    "        max_percent = max_percent_height\n",
    "    if percent > max_percent:\n",
    "        percent = max_percent\n",
    "    width = int(image.shape[1] * percent / 100)\n",
    "    height = int(image.shape[0] * percent / 100)\n",
    "    image = image + int(percent * color_scale_rate)\n",
    "    result = cv2.resize(image, (width, height), interpolation = cv2.INTER_AREA)\n",
    "    return result, percent\n",
    "\n",
    "def invariantMatchTemplate(rgbimage, rgbtemplate, method, matched_thresh, rot_range, rot_interval, scale_range, scale_interval, rm_redundant):\n",
    "    \"\"\"\n",
    "    rgbimage: RGB image where the search is running.\n",
    "    rgbtemplate: RGB searched template. It must be not greater than the source image and have the same data type.\n",
    "    method: [String] Parameter specifying the comparison method\n",
    "    matched_thresh: [Float] Setting threshold of matched results(0~1).\n",
    "    rgbdiff_thresh: [Float] Setting threshold of average RGB difference between template and source image.\n",
    "    rot_range: [Integer] Array of range of rotation angle in degrees. Example: [0,360]\n",
    "    rot_interval: [Integer] Interval of traversing the range of rotation angle in degrees.\n",
    "    scale_range: [Integer] Array of range of scaling in percentage. Example: [50,200]\n",
    "    scale_interval: [Integer] Interval of traversing the range of scaling in percentage.\n",
    "    rm_redundant: [Boolean] Option for removing redundant matched results based on the width and height of the template.\n",
    "\n",
    "    Returns: List of satisfied matched points in format [[point.x, point.y], angle, scale, matched_thresh].\n",
    "    \"\"\"\n",
    "    image_maxwh = rgbimage.shape\n",
    "    height, width, numchannel = rgbtemplate.shape\n",
    "    all_points = []\n",
    "    for next_angle in range(rot_range[0], rot_range[1], rot_interval):\n",
    "        for next_scale in range(scale_range[0], scale_range[1], scale_interval):\n",
    "            scaled_template, actual_scale = scale_image(rgbtemplate, next_scale, image_maxwh)\n",
    "            if next_angle == 0:\n",
    "                rotated_template = scaled_template\n",
    "            else:\n",
    "                rotated_template = rotate_image(scaled_template, next_angle)\n",
    "            matched_points = cv2.matchTemplate(rgbimage, rotated_template, method, None, rotated_template.copy())\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(matched_points)\n",
    "            if method == cv2.TM_SQDIFF_NORMED:  # cv.TM_SQDIFF_NORMED is the most similar when it is the smallest, most similar when the others are the largest\n",
    "                max_loc = min_loc\n",
    "                max_val = 1 - max_val\n",
    "            if max_val >= matched_thresh:\n",
    "                all_points.append([max_loc, next_angle, actual_scale, max_val])\n",
    "    all_points = sorted(all_points, key=lambda x: -x[3])\n",
    "    if rm_redundant == True:\n",
    "        lone_points_list = []\n",
    "        visited_points_list = []\n",
    "        for point_info in all_points:\n",
    "            point = point_info[0]\n",
    "            scale = point_info[2]\n",
    "            all_visited_points_not_close = True\n",
    "            if len(visited_points_list) != 0:\n",
    "                for visited_point in visited_points_list:\n",
    "                    if ((abs(visited_point[0] - point[0]) < (width * scale / 100)) and (abs(visited_point[1] - point[1]) < (height * scale / 100))):\n",
    "                        all_visited_points_not_close = False\n",
    "                if all_visited_points_not_close == True:\n",
    "                    lone_points_list.append(point_info)\n",
    "                    visited_points_list.append(point)\n",
    "            else:\n",
    "                lone_points_list.append(point_info)\n",
    "                visited_points_list.append(point)\n",
    "        points_list = lone_points_list\n",
    "    else:\n",
    "        points_list = all_points\n",
    "    return points_list\n",
    "\n",
    "\n",
    "def main():\n",
    "    img_rgb = cv2.imread('./templates/2/part8.png')\n",
    "    template_rgb = cv2.imread('./templates/2/part9.png')\n",
    "    height, width = template_rgb.shape[0:2]\n",
    "    points_list = invariantMatchTemplate(img_rgb, template_rgb, cv2.TM_CCORR_NORMED, 0.8, [-5,5], 1, [90,110], 2, True)\n",
    "    fig, ax = plt.subplots(1)\n",
    "    #plt.gcf().canvas.set_window_title('Template Matching Results')\n",
    "    ax.imshow(img_rgb)\n",
    "    centers_list = []\n",
    "    print(f\"len(points_list) {len(points_list)}\")\n",
    "    for point_info in points_list:\n",
    "        point = point_info[0]\n",
    "        print(\"Point:\", point)\n",
    "        angle = point_info[1]\n",
    "        print(\"Corresponding angle:\", angle)\n",
    "        scale = point_info[2]\n",
    "        print(\"Corresponding scale:\", scale)\n",
    "        matched_thresh = point_info[3]\n",
    "        print(\"Corresponding matched_thresh:\", matched_thresh)\n",
    "        centers_list.append([point, scale])\n",
    "        plt.scatter(point[0] + (width/2)*scale/100, point[1] + (height/2)*scale/100, s=20, color=\"red\")\n",
    "        plt.scatter(point[0], point[1], s=20, color=\"green\")\n",
    "        rectangle = patches.Rectangle((point[0], point[1]), width*scale/100, height*scale/100, color=\"red\", alpha=0.50, label='Matched box')\n",
    "        box = patches.Rectangle((point[0], point[1]), width*scale/100, height*scale/100, color=\"green\", alpha=0.50, label='Bounding box')\n",
    "        transform = mpl.transforms.Affine2D().rotate_deg_around(point[0] + width/2*scale/100, point[1] + height/2*scale/100, angle) + ax.transData\n",
    "        rectangle.set_transform(transform)\n",
    "        ax.add_patch(rectangle)\n",
    "        ax.add_patch(box)\n",
    "        plt.legend(handles=[rectangle,box])\n",
    "        print()\n",
    "    #plt.grid(True)\n",
    "    plt.show()\n",
    "    fig2, ax2 = plt.subplots(1)\n",
    "    #plt.gcf().canvas.set_window_title('Template Matching Results')\n",
    "    ax2.imshow(img_rgb)\n",
    "    for point_info in centers_list:\n",
    "        point = point_info[0]\n",
    "        scale = point_info[1]\n",
    "        plt.scatter(point[0]+width/2*scale/100, point[1]+height/2*scale/100, s=20, color=\"red\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# USAGE\n",
    "# python match.py --template cod_logo.png --images images\n",
    "\n",
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-t\", \"--template\", required=True, help=\"Path to template image\")\n",
    "ap.add_argument(\"-i\", \"--images\", required=True,\n",
    "\thelp=\"Path to images where template will be matched\")\n",
    "ap.add_argument(\"-v\", \"--visualize\",\n",
    "\thelp=\"Flag indicating whether or not to visualize each iteration\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# load the image image, convert it to grayscale, and detect edges\n",
    "template = cv2.imread(args[\"template\"])\n",
    "template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "template = cv2.Canny(template, 50, 200)\n",
    "(tH, tW) = template.shape[:2]\n",
    "cv2.imshow(\"Template\", template)\n",
    "\n",
    "# loop over the images to find the template in\n",
    "for imagePath in glob.glob(args[\"images\"] + \"/*.jpg\"):\n",
    "\t# load the image, convert it to grayscale, and initialize the\n",
    "\t# bookkeeping variable to keep track of the matched region\n",
    "\timage = cv2.imread(imagePath)\n",
    "\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\tfound = None\n",
    "\n",
    "\t# loop over the scales of the image\n",
    "\tfor scale in np.linspace(0.2, 1.0, 20)[::-1]:\n",
    "\t\t# resize the image according to the scale, and keep track\n",
    "\t\t# of the ratio of the resizing\n",
    "\t\tresized = imutils.resize(gray, width = int(gray.shape[1] * scale))\n",
    "\t\tr = gray.shape[1] / float(resized.shape[1])\n",
    "\n",
    "\t\t# if the resized image is smaller than the template, then break\n",
    "\t\t# from the loop\n",
    "\t\tif resized.shape[0] < tH or resized.shape[1] < tW:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\t# detect edges in the resized, grayscale image and apply template\n",
    "\t\t# matching to find the template in the image\n",
    "\t\tedged = cv2.Canny(resized, 50, 200)\n",
    "\t\tresult = cv2.matchTemplate(edged, template, cv2.TM_CCOEFF)\n",
    "\t\t(_, maxVal, _, maxLoc) = cv2.minMaxLoc(result)\n",
    "\n",
    "\t\t# check to see if the iteration should be visualized\n",
    "\t\tif args.get(\"visualize\", False):\n",
    "\t\t\t# draw a bounding box around the detected region\n",
    "\t\t\tclone = np.dstack([edged, edged, edged])\n",
    "\t\t\tcv2.rectangle(clone, (maxLoc[0], maxLoc[1]),\n",
    "\t\t\t\t(maxLoc[0] + tW, maxLoc[1] + tH), (0, 0, 255), 2)\n",
    "\t\t\tcv2.imshow(\"Visualize\", clone)\n",
    "\t\t\tcv2.waitKey(0)\n",
    "\n",
    "\t\t# if we have found a new maximum correlation value, then ipdate\n",
    "\t\t# the bookkeeping variable\n",
    "\t\tif found is None or maxVal > found[0]:\n",
    "\t\t\tfound = (maxVal, maxLoc, r)\n",
    "\n",
    "\t# unpack the bookkeeping varaible and compute the (x, y) coordinates\n",
    "\t# of the bounding box based on the resized ratio\n",
    "\t(_, maxLoc, r) = found\n",
    "\t(startX, startY) = (int(maxLoc[0] * r), int(maxLoc[1] * r))\n",
    "\t(endX, endY) = (int((maxLoc[0] + tW) * r), int((maxLoc[1] + tH) * r))\n",
    "\n",
    "\t# draw a bounding box around the detected result and display the image\n",
    "\tcv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "\tcv2.imshow(\"Image\", image)\n",
    "\tcv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Method: 0: SQDIFF | 1: SQDIFF NORMED | 2: TM CCORR | 3: TM CCORR NORMED | 4: TM COEFF | 5: TM COEFF NORMED\n",
    "img_path = \"./templates/2/part3.png\"\n",
    "tem_path = \"./templates/2/part7.png\"\n",
    "\n",
    "def test():\n",
    "    global img_path, tem_path\n",
    "\n",
    "    def findImgthres(image_path, template_path, mask=False, method=1, thres=.95):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED) # cv2.IMREAD_COLOR (cv2.IMREAD_UNCHANGED)\n",
    "        tem = cv2.imread(tem_path, cv2.IMREAD_UNCHANGED) # cv2.IMREAD_COLOR (cv2.IMREAD_UNCHANGED)\n",
    "        # Match template with and without mask\n",
    "\n",
    "\n",
    "        if mask and tem.shape[2] == 4:\n",
    "            alpha_channel = np.array(cv2.split(tem)[3])\n",
    "            cv2.imwrite(\"./mask.png\", alpha_channel)\n",
    "            result = cv2.matchTemplate(img, tem, method, mask=alpha_channel)\n",
    "        else:\n",
    "            #result = cv2.matchTemplate(img, tem, method)\n",
    "            result = cv.matchTemplate(img, tem, method, None, tem)\n",
    "        min_val, max_val, min_loc, max_loc = cv.minMaxLoc(result)\n",
    "        # Nomrmalize result data to percent (0-1)\n",
    "        #result = cv2.normalize(result, None, 0, 1, cv2.NORM_MINMAX, -1)\n",
    "\n",
    "        # Invert Image to work similar across all methods!\n",
    "        #if method == 0 or method == 1: result = (1 - result)\n",
    "\n",
    "        result_list = np.where(result >= thres)\n",
    "\n",
    "        return result, result_list, max_val, max_loc\n",
    "\n",
    "    tmp_source = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    tmp_mask_source = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    tmp_tem = cv2.imread(tem_path, cv2.IMREAD_COLOR)\n",
    "    result = findImgthres(img_path, tem_path, False, cv2.TM_CCORR_NORMED)\n",
    "    mask_result = findImgthres(img_path, tem_path, True, cv2.TM_CCORR_NORMED)\n",
    "    \"\"\"\n",
    "    # Mark original Image with mask\n",
    "    matchLoc = mask_result[1]\n",
    "    if matchLoc is not None:\n",
    "        for loc in matchLoc:\n",
    "            cv2.rectangle(tmp_mask_source, tuple(loc)[::-1], (loc[1] + tmp_tem.shape[1], loc[0] + tmp_tem.shape[0]), (0,0,0), 1)\n",
    "\n",
    "    # Mark original Image without mask\n",
    "    matchLoc = result[1]\n",
    "    if matchLoc is not None:\n",
    "        for loc in matchLoc:\n",
    "            cv2.rectangle(tmp_source, tuple(loc)[::-1], (loc[1] + tmp_tem.shape[1], loc[0] + tmp_tem.shape[0]), (0,0,0), 1)\n",
    "    \"\"\"\n",
    "    # Save Images\n",
    "    _dir = os.path.dirname('./')\n",
    "    cv2.imwrite(os.path.join(_dir, \"source.png\") , tmp_source)\n",
    "    cv2.imwrite(os.path.join(_dir, \"mask_source.png\") , tmp_mask_source)\n",
    "    cv2.imwrite(os.path.join(_dir, \"result.png\") , 255*result[0])\n",
    "    cv2.imwrite(os.path.join(_dir, \"mask_result.png\") , 255*mask_result[0])\n",
    "\n",
    "    # Output Result\n",
    "    print(f\"[NO MASK] {result[2]} Match Locs: {result[3]}\")\n",
    "    print(f\"[MASK] {mask_result[2]} Match Locs: {mask_result[3]}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "\n",
    "img_path = \"./templates/2/part4.png\"\n",
    "tem_path = \"./templates/2/part7.png\"\n",
    "\n",
    "def test():\n",
    "    global img_path, tem_path\n",
    "\n",
    "    def findImgthres(method, thres=.95):\n",
    "        img = cv2.imread(img_path) # cv2.IMREAD_COLOR (cv2.IMREAD_UNCHANGED)\n",
    "        tem = cv2.imread(tem_path) # cv2.IMREAD_COLOR (cv2.IMREAD_UNCHANGED)\n",
    "        # Match template with and without mask\n",
    "\n",
    "        result = cv.matchTemplate(img, tem, method, None, tem)\n",
    "        min_val, max_val, min_loc, max_loc = cv.minMaxLoc(result)\n",
    "        result_list = np.where(result >= thres)\n",
    "        return result, result_list, max_val, max_loc\n",
    "\n",
    "    mask_result = findImgthres(cv2.TM_CCORR_NORMED)\n",
    "\n",
    "    print(f\"[MASK] {mask_result[2]} Match Locs: {mask_result[3]}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "#import numpy as np\n",
    "\n",
    "def template_demo():\n",
    "    target = cv.imread(\"./templates/2/part4.png\")\n",
    "    tpl = cv.imread(\"./templates/2/part7.png\")\n",
    "\n",
    "    res = cv.matchTemplate(target, tpl, cv.TM_CCORR_NORMED, None, tpl)\n",
    "    min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "    print(max_val,max_loc)\n",
    "template_demo()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(True, [[(22, 61), 0, 100, 1.0000001192092896]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, -angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result\n",
    "\n",
    "def scale_image(image, percent, maxwh):\n",
    "    color_scale_rate = 0\n",
    "    max_width = maxwh[1]\n",
    "    max_height = maxwh[0]\n",
    "    max_percent_width = max_width / image.shape[1] * 100\n",
    "    max_percent_height = max_height / image.shape[0] * 100\n",
    "    max_percent = 0\n",
    "    if max_percent_width < max_percent_height:\n",
    "        max_percent = max_percent_width\n",
    "    else:\n",
    "        max_percent = max_percent_height\n",
    "    if percent > max_percent:\n",
    "        percent = max_percent\n",
    "    width = int(image.shape[1] * percent / 100)\n",
    "    height = int(image.shape[0] * percent / 100)\n",
    "    image = image + int(percent * color_scale_rate)\n",
    "    result = cv2.resize(image, (width, height), interpolation = cv2.INTER_AREA)\n",
    "    return result, percent\n",
    "\n",
    "def invariantMatchTemplate(rgbimage, rgbtemplate, method, matched_thresh, rot_range, rot_interval, scale_range, scale_interval, rm_redundant):\n",
    "    \"\"\"\n",
    "    rgbimage: RGB image where the search is running.\n",
    "    rgbtemplate: RGB searched template. It must be not greater than the source image and have the same data type.\n",
    "    method: [String] Parameter specifying the comparison method\n",
    "    matched_thresh: [Float] Setting threshold of matched results(0~1).\n",
    "    rgbdiff_thresh: [Float] Setting threshold of average RGB difference between template and source image.\n",
    "    rot_range: [Integer] Array of range of rotation angle in degrees. Example: [0,360]\n",
    "    rot_interval: [Integer] Interval of traversing the range of rotation angle in degrees.\n",
    "    scale_range: [Integer] Array of range of scaling in percentage. Example: [50,200]\n",
    "    scale_interval: [Integer] Interval of traversing the range of scaling in percentage.\n",
    "    rm_redundant: [Boolean] Option for removing redundant matched results based on the width and height of the template.\n",
    "\n",
    "    Returns: List of satisfied matched points in format [[point.x, point.y], angle, scale, matched_thresh].\n",
    "    \"\"\"\n",
    "    image_maxwh = rgbimage.shape\n",
    "    height, width, numchannel = rgbtemplate.shape\n",
    "    all_points = []\n",
    "    for next_angle in range(rot_range[0], rot_range[1], rot_interval):\n",
    "        for next_scale in range(scale_range[0], scale_range[1], scale_interval):\n",
    "            scaled_template, actual_scale = scale_image(rgbtemplate, next_scale, image_maxwh)\n",
    "            if next_angle == 0:\n",
    "                rotated_template = scaled_template\n",
    "            else:\n",
    "                rotated_template = rotate_image(scaled_template, next_angle)\n",
    "            template_gray = cv2.cvtColor(rotated_template,cv2.COLOR_BGR2GRAY)\n",
    "            contours, _  = cv2.findContours(template_gray, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            areas = [cv2.contourArea(c) for c in contours]\n",
    "            max_index = np.argmax(areas)\n",
    "            cnt=contours[max_index]\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            #print(x, y, w, h)\n",
    "            rotated_template = rotated_template[y:y+h, x:x+w]\n",
    "\n",
    "            matched_points = cv2.matchTemplate(rgbimage, rotated_template, method, None, rotated_template.copy())\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(matched_points)\n",
    "            if max_val >= matched_thresh:\n",
    "                #print(f\"max_loc {max_loc}\")\n",
    "                max_loc = (max_loc[0]-x, max_loc[1]-y)\n",
    "                #print(f\"max_loc {max_loc}\")\n",
    "                all_points.append([max_loc, next_angle, actual_scale, max_val])\n",
    "    all_points = sorted(all_points, key=lambda x: -x[3])\n",
    "    if rm_redundant == True:\n",
    "        lone_points_list = []\n",
    "        visited_points_list = []\n",
    "        for point_info in all_points:\n",
    "            point = point_info[0]\n",
    "            scale = point_info[2]\n",
    "            all_visited_points_not_close = True\n",
    "            if len(visited_points_list) != 0:\n",
    "                for visited_point in visited_points_list:\n",
    "                    if ((abs(visited_point[0] - point[0]) < (width * scale / 100)) and (abs(visited_point[1] - point[1]) < (height * scale / 100))):\n",
    "                        all_visited_points_not_close = False\n",
    "                if all_visited_points_not_close == True:\n",
    "                    lone_points_list.append(point_info)\n",
    "                    visited_points_list.append(point)\n",
    "            else:\n",
    "                lone_points_list.append(point_info)\n",
    "                visited_points_list.append(point)\n",
    "        points_list = lone_points_list\n",
    "    else:\n",
    "        points_list = all_points\n",
    "    return points_list\n",
    "\n",
    "\n",
    "def MatchTemplate(image_path, template_path, maxShiftPix):\n",
    "    img_rgb = cv2.imread('./templates/2/nest_part.png')\n",
    "    template_rgb = cv2.imread('./templates/2/nest1.png')\n",
    "\n",
    "    #img_rgb = cv2.imread(image_path)\n",
    "    #template_rgb = cv2.imread(template_path)\n",
    "    points_list = invariantMatchTemplate(img_rgb, template_rgb, cv2.TM_CCORR_NORMED, 0.95, [-5,5+1], 1, [100,100+1], 1, True)\n",
    "    points_list = list(filter(lambda x: (abs(x[0][0]) < maxShiftPix  and abs(x[0][1]) < maxShiftPix), points_list))\n",
    "    ok = (len(points_list) == 1)\n",
    "    return ok, points_list\n",
    "MatchTemplate(\"\",\"\", 135)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server started at http://192.168.131.1:9001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 15\u001B[0m\n\u001B[0;32m     13\u001B[0m server \u001B[38;5;241m=\u001B[39m ps\u001B[38;5;241m.\u001B[39mStreamer(address, stream_props)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mServer started at\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttp://\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m address[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(address[\u001B[38;5;241m1\u001B[39m]))\n\u001B[1;32m---> 15\u001B[0m \u001B[43mserver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mserve_forever\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mServer continue\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mC:\\Program Files\\Python310\\lib\\socketserver.py:232\u001B[0m, in \u001B[0;36mBaseServer.serve_forever\u001B[1;34m(self, poll_interval)\u001B[0m\n\u001B[0;32m    229\u001B[0m selector\u001B[38;5;241m.\u001B[39mregister(\u001B[38;5;28mself\u001B[39m, selectors\u001B[38;5;241m.\u001B[39mEVENT_READ)\n\u001B[0;32m    231\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__shutdown_request:\n\u001B[1;32m--> 232\u001B[0m     ready \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpoll_interval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    233\u001B[0m     \u001B[38;5;66;03m# bpo-35017: shutdown() called during select(), exit immediately.\u001B[39;00m\n\u001B[0;32m    234\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__shutdown_request:\n",
      "File \u001B[1;32mC:\\Program Files\\Python310\\lib\\selectors.py:324\u001B[0m, in \u001B[0;36mSelectSelector.select\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    322\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    323\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 324\u001B[0m     r, w, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_select\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_readers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_writers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[0;32m    326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "File \u001B[1;32mC:\\Program Files\\Python310\\lib\\selectors.py:315\u001B[0m, in \u001B[0;36mSelectSelector._select\u001B[1;34m(self, r, w, _, timeout)\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_select\u001B[39m(\u001B[38;5;28mself\u001B[39m, r, w, _, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m--> 315\u001B[0m     r, w, x \u001B[38;5;241m=\u001B[39m \u001B[43mselect\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m r, w \u001B[38;5;241m+\u001B[39m x, []\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import pyshine as ps\n",
    "import socket\n",
    "HTML = f\"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<center><img src=\"stream.mjpg\" width='640' height='480' autoplay playsinline></center>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "address = (socket.gethostbyname(socket.gethostname()), 9001)  # Enter your IP address\n",
    "stream_props = ps.StreamProps\n",
    "stream_props.set_Page(stream_props, HTML)\n",
    "server = ps.Streamer(address, stream_props)\n",
    "print('Server started at', 'http://' + address[0] + ':' + str(address[1]))\n",
    "server.serve_forever()\n",
    "print('Server continue')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 64 74 69\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "nest = cv2.imread('./templates/2/nest.png')\n",
    "nest_part = cv2.imread('./templates/2/nest_part.png')\n",
    "\n",
    "nest_diff = cv2.compare(nest_part, nest, cv2.CMP_NE)\n",
    "\n",
    "alpha_channel = cv2.cvtColor(nest_diff,cv2.COLOR_BGR2GRAY)\n",
    "b_channel, g_channel, r_channel = cv2.split(nest_part)\n",
    "b_channel = cv2.bitwise_and(b_channel,b_channel,mask = alpha_channel)\n",
    "g_channel = cv2.bitwise_and(g_channel,g_channel,mask = alpha_channel)\n",
    "r_channel = cv2.bitwise_and(r_channel,r_channel,mask = alpha_channel)\n",
    "\n",
    "nest_mask = cv2.merge((b_channel, g_channel, r_channel, alpha_channel ))\n",
    "\n",
    "#cv2.imwrite('./templates/2/nest_diff.png', nest_diff)\n",
    "cv2.imwrite('./templates/2/nest_mask.png', nest_mask)\n",
    "contours, _  = cv2.findContours(alpha_channel, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "x,y,h,w = cv2.boundingRect(contours[0])\n",
    "print(x,y,h,w)\n",
    "#cv2.imwrite('./templates/2/contours.png', contours)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 12 122 168\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "template_rgb = cv2.imread('./templates/2/part6.png', cv2.IMREAD_UNCHANGED)\n",
    "template_gray = cv2.cvtColor(template_rgb,cv2.COLOR_BGR2GRAY)\n",
    "contours, _  = cv2.findContours(template_gray, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "areas = [cv2.contourArea(c) for c in contours]\n",
    "max_index = np.argmax(areas)\n",
    "cnt=contours[max_index]\n",
    "x,y,w,h = cv2.boundingRect(cnt)\n",
    "print(x,y,w,h)\n",
    "crop_template = template_rgb[y:y+h, x:x+w]\n",
    "\n",
    "cv2.imwrite('./templates/2/crop_template.png', crop_template)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}